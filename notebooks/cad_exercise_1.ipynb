{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Implementing linear regression\n",
    "The optimal parameters of a linear regression model given a training dataset of features **X** and  targets **y** can be obtained with the closed-form solution for minimization of the loss function:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}{J(\\theta)=\\|X \\theta-y\\|_{2}^{2}} \\\\ {\\nabla_{\\theta} J=0} \\\\ {\\theta=\\left(X^{\\top} X\\right)^{-1} X^{\\top} y}\\end{array}\n",
    "$$\n",
    "\n",
    "The function `ls_solve()` that you have implemented in the point-based registration practical (`# SECTION 2` of the `registration.py` module) can be reused to solve for the parameters $\\theta$.\n",
    "\n",
    "The `linear_regression()` Python script in `# SECTION 1` of the `cad_tests.py` module reads a toy dataset split into training, validation and testing subsets, computes the parameters of a linear regression model and visualises the results for the training and testing datasets. The toy dataset consists of a single feature and a target variable. For example, the target that we want to predict can be a person's systolic blood pressure and age can be the single feature that describes the person. Such a \"small\" problem is not often encountered in practice but it can be very illustrative for this technique (in the project work you will work with a more \"practical\" medical image analysis problem).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A)\n",
    "The first section of `linear_regression()` loads the training, validation and testing datasets that will be used for training and evaluation of the linear regression model. It also shows a plot of the feature vs. the target variable. We can observe from the plot that the value of the target tends to increase together with the value of the feature.\n",
    "\n",
    "<img src=\"../notebooks/assets/linreg_training_data.png\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "### QUESTION:\n",
    "What is role of these three subsets in training and evaluating machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B)\n",
    "### EXERCISE:\n",
    "Implement the missing functionality of `linear_regression()` that computes the parameters `Theta` of the linear regression model. Note that you will have to add a column of all ones to the data matrix, for which you can use the provided `addones()` function in the `cad_util.py` module.\n",
    "\n",
    "If you have implemented this correctly, the results for the training set should look like in the figure below. \n",
    "\n",
    "<img src=\"../notebooks/assets/linreg_training.png\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from cad_tests import linear_regression\n",
    "\n",
    "E_validation, E_test = linear_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C)\n",
    "### EXERCISE:\n",
    "How can you compute the error of the linear regression model for the optimal parameters? Implement this at the end of `linear_regression()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(E_validation)\n",
    "print(E_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Polynomial regression and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that after examining the results from the linear regression model, your conclusion is that a quadratic model might be a better fit for the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A)\n",
    "### EXERCISE:\n",
    "Use the existing code for linear regression to implement and evaluate such a model. You can make a copy of `linear_regression()` called `quadratic_regression()` and work there.\n",
    "\n",
    "If you have implemented this correctly, the results for the training set should look like in the figure below:\n",
    "\n",
    "<img src=\"../notebooks/assets/quadreg_training.png\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from cad_tests import quadratic_regression\n",
    "\n",
    "E_validation, E_test = quadratic_regression()\n",
    "print(E_validation)\n",
    "print(E_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B)\n",
    "### QUESTION:\n",
    "You now have implemented both linear and quadratic regression. Compare the quadratic regression to the linear regression model. Which model would you choose and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C)\n",
    "### QUESTION:\n",
    "After choosing one of the two models, you have to report the error. For which dataset should you report the error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
